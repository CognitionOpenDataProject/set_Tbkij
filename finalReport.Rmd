---
title: "COD Reproducibility Report"
output:
  html_document:
    toc: true
    toc_float: true
---

#### Article ID: Tbkij
#### Pilot: Lawrence Liu
#### Co-pilot: Tom Hardwicke
#### Start date: Mar 23 2017
#### End date: May 11 2017
#### Final verification: Tom Hardwicke
#### Date: Nov 13 2017


-------

#### Methods summary: 
The participants were tested in a quiet dark room, and they looked at a monitor for instructions while using a piece of felt in their hand to obstruct an infrared beam in front of a sensor. At the start of a trial, a participant was instructed to hold still while fixating on the center of a clock with a second hand.

There were 4 conditions. In the Event (E) condition, participants listened to a tone but took no action with the cloth. In the Event-Action (EA) condition, participants were asked to lift the cloth away from the IR beam when they heard a tone. In the Action-Event (AE) and Action-Event-Action (AEA) conditions, participants were asked to move their hand at a random time of their choosing during the clock's second hand's second full rotation, after which a tone would be played. In the AEA condition, participants were instructed to lift the cloth after they heard the tone. After each trial, participants were asked to report the position of the clock's second hand when they heard the tone. After each trial, they were given feedback about whether their reported position was clockwise or counterclockwise of the actual position.

Each participant practiced on all 4 conditions until their performance became stable. Then, they each underwent 3 experimental sessions of 84 trials per session. Each session consisted of four 21-trial blocks, and each block contained trials of the same condition. The condition order that each participation saw was randomized.

The dependent variable is average error between the guessed second hand position and the actual second hand position on any trial for all trials within each condition.

------

#### Target outcomes: 

> All the participants initiated their actions during the second rotation of the Libet clock in the AE and AEA conditions. In addition, the response times for the second movement in the AEA condition suggest that participants had followed the instruction to respond to the tone rather than simply making two movements, one after the other without reference to the tone. [If the time between the tone and the second movement was 100 ms or less, then that trial was excluded from analysis.] On average, the response time to the tone was 310 ± 67 ms, a value that is consistent with reacting to the tone rather than simply making a ‘double’ movement. This means that the average interval between the two movements was more than 500 ms, given that the tone always occurred 250 ms after the first movement – an inter-movement interval that suggests that the movements were independent rather than linked. Moreover, after excluding one outlier, the Pearson Product Moment correlation (r) across participants between response times in the EA condition and the AEA condition was 0.54 (p < 0.05), again suggesting that the second action in AEA condition was a reaction to the tone as was the action in EA condition. Fig. 2 depicts the mean difference scores (perceived minus real stimulus onsets) for all participants across conditions. The data from one participant who did not understand the task was excluded. The mean ± SD difference scores for the E, EA, AE and AEA conditions were 141.2 ± 45.1 ms, 200.5 ± 61.8 ms, 20.5 ± 134.3 ms, and 129.4 ± 116.2 ms respectively. The perceived delay in the tone was larger in the EA condition (p = 0.002) and smaller in the AE condition (p = 0.001) than in the E condition. There was no significant difference between the perceived delay in the AEA condition and that in the E condition (p = 0.683).

> A one-way ANOVA revealed a significant effect of conditions (F(2, 36) = 20.62, p < 0.001) on the standardized difference scores (where the difference scores for each participant in the E condition was subtracted from his or her difference score in the EA, AE, and AEA conditions). The post hoc tests revealed that the standardized difference scores were larger (more positive) in the EA condition than in the AE and AEA conditions (p = 0.000 and p = 0.012 respectively). The standardized difference score was smaller (less positive) in the AE condition than in the AEA condition (p = 0.003). In summary, temporal binding occurred both when an action triggered an event and when an event triggered an action. However, the binding (as indicated by a smaller perceived delay) was decreased when an action followed an action – event sequence.

------

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)

# prepare an empty report object, we will update this each time we run compareValues2()
reportObject <- data.frame("Article_ID" = NA, "valuesChecked" = 0, "eyeballs" = 0, "Total_df" = 0, "Total_p" = 0, "Total_mean" = 0, "Total_sd" = 0, "Total_se" = 0, "Total_ci" = 0, "Total_bf" = 0, "Total_t" = 0, "Total_F" = 0, "Total_es" = 0, "Total_median" = 0, "Total_irr" = 0, "Total_r" = 0, "Total_z" = 0, "Total_coeff" = 0, "Total_n" = 0, "Total_x2" = 0, "Total_other" = 0, "Insufficient_Information_Errors" = 0, "Decision_Errors" = 0, "Major_Numerical_Errors" = 0, "Minor_Numerical_Errors" = 0, "Major_df" = 0, "Major_p" = 0, "Major_mean" = 0, "Major_sd" = 0, "Major_se" = 0, "Major_ci" = 0, "Major_bf" = 0, "Major_t" = 0, "Major_F" = 0, "Major_es" = 0, "Major_median" = 0, "Major_irr" = 0, "Major_r" = 0, "Major_z" = 0, "Major_coeff" = 0, "Major_n" = 0, "Major_x2" = 0, "Major_other" = 0, "affectsConclusion" = NA, "error_typo" = 0, "error_specification" = 0, "error_analysis" = 0, "error_data" = 0, "error_unidentified" = 0, "Author_Assistance" = NA, "resolved_typo" = 0, "resolved_specification" = 0, "resolved_analysis" = 0, "resolved_data" = 0, "correctionSuggested" = NA, "correctionPublished" = NA)
```

## Step 1: Load packages

Some useful packages are being loaded below.

```{r}
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(broom) # for neat model output
library(CODreports) # custom report functions
```

## Step 2: Load data

```{r}
perceived_times <- read_csv("data/data1.csv")
reaction_times <- read_csv("data/data2.csv")
```

## Step 3: Tidy data

Organise the data in 'Tidy' format:

```{r}
#Long data frames
pt_long <- perceived_times %>%
  gather(condition, perceived_time_in_ms, E, EA, AE, AEA)
rt_long <- reaction_times %>%
  gather(condition, reaction_time_in_ms, E, EA, AE, AEA) %>%
  filter(reaction_time_in_ms != "n.a.")

#Clarify column names
p_times <- perceived_times %>%
  rename(E_pt = E, EA_pt = EA, AE_pt = AE, AEA_pt = AEA)
r_times <- reaction_times %>%
  rename(EA_rt = EA, AEA_rt = AEA) %>%
  mutate(EA_rt = EA_rt * 1000, AEA_rt = AEA_rt * 1000)

#Join data frames for wide form df
df <- bind_cols(p_times,r_times %>% subset(select=c(EA_rt, AEA_rt)))
```

## Step 4: Run analysis

### Descriptive statistics

Try to reproduce the following target outcomes:

> On average, the response time to the tone was 310 ± 67 ms, a value that is consistent with reacting to the tone rather than simply making a ‘double’ movement.

```{r}
reportObject <- compareValues2(reportedValue = "310", obtainedValue = mean(df$AEA_rt), valueType = 'mean')
reportObject <- compareValues2(reportedValue = "67", obtainedValue = sd(df$AEA_rt), valueType = 'sd')
```

### Inferential statistics

Now we attempt to reproduce the following target outcomes:

> after excluding one outlier, the Pearson Product Moment correlation (r) across participants between response times in the EA condition and the AEA condition was 0.54 (p < 0.05), again suggesting that the second action in AEA condition was a reaction to the tone as was the action in EA condition. 

NB we initially ran into problems here as we did not know the identity of the outlier, and could not proceed with this aspect of the analysis. However, we were able to contact the original authors who identified the participant for us as "FM016"

```{r}
df_drop <- df %>% filter(Sbj != "FM016") # remove participant id FM016
cor.out <- cor.test(df_drop$EA_rt, df_drop$AEA_rt)

reportObject <- compareValues2(reportedValue = "0.54", obtainedValue = cor.out$estimate, valueType = 'r')
reportObject <- compareValues2(reportedValue = "eyeballMATCH", obtainedValue = cor.out$p.value, valueType = 'p')
```

The values match.

Let's now try and reproduce the following outcomes:

> Fig. 2 depicts the mean difference scores (perceived minus real stimulus onsets) for all participants across conditions. The data from one participant who did not understand the task was excluded. 

Initially we did not know the identity of this participant and could not complete the analysis. As a result we coded an insufficient information error. However, contact with the original authors revealed that this participant was "FM039". Here we remove that participant before proceeding:

```{r}
df_drop2 <- df %>%
  filter(Sbj != "FM039")
```

We should now have 19 participants:

```{r}
nrow(df_drop2)
```

Let's try and reproduce these values:

> The mean ± SD difference scores for the E, EA, AE and AEA conditions were 141.2 ± 45.1 ms, 200.5 ± 61.8 ms, 20.5 ± 134.3 ms, and 129.4 ± 116.2 ms respectively. 

```{r}
sumTab <- df_drop2 %>% 
  select(-EA_rt,-AEA_rt) %>% 
  gather(condition, pt, E_pt:AEA_pt, factor_key=TRUE) %>% 
  group_by(condition) %>%
  summarise(mean(pt), sd(pt), n())
sumTab
```

The values appear to match. Let's double check:

```{r}
m1 <- sumTab %>% filter(condition == "E_pt") %>% pull(`mean(pt)`)
reportObject <- compareValues2(reportedValue = "141.2", obtainedValue = m1, valueType = 'mean')
sd1 <- sumTab %>% filter(condition == "E_pt") %>% pull(`sd(pt)`)
reportObject <- compareValues2(reportedValue = "45.1", obtainedValue = sd1, valueType = 'sd')

m2 <- sumTab %>% filter(condition == "EA_pt") %>% pull(`mean(pt)`)
reportObject <- compareValues2(reportedValue = "200.5", obtainedValue = m2, valueType = 'mean')
sd2 <- sumTab %>% filter(condition == "EA_pt") %>% pull(`sd(pt)`)
reportObject <- compareValues2(reportedValue = "61.8", obtainedValue = sd2, valueType = 'sd')

m3 <- sumTab %>% filter(condition == "AE_pt") %>% pull(`mean(pt)`)
reportObject <- compareValues2(reportedValue = "20.5", obtainedValue = m3, valueType = 'mean')
sd3 <- sumTab %>% filter(condition == "AE_pt") %>% pull(`sd(pt)`)
reportObject <- compareValues2(reportedValue = "134.3", obtainedValue = sd3, valueType = 'sd')

m4 <- sumTab %>% filter(condition == "AEA_pt") %>% pull(`mean(pt)`)
reportObject <- compareValues2(reportedValue = "129.4", obtainedValue = m4, valueType = 'mean')
sd4 <- sumTab %>% filter(condition == "AEA_pt") %>% pull(`sd(pt)`)
reportObject <- compareValues2(reportedValue = "116.2", obtainedValue = sd4, valueType = 'sd')
```

> The perceived delay in the tone was larger in the EA condition (p = 0.002) and smaller in the AE condition (p = 0.001) than in the E condition. There was no significant difference between the perceived delay in the AEA condition and that in the E condition (p = 0.683).

This was initially an insufficient information error as the statistical test was not explictly identified. However, the original authors informed us that they had used t-tests here. They noted that paired t-tests should have been employed, but they actually used unpaired t-tests.

```{r}
p1 <- t.test(df_drop2$EA_pt, df_drop2$E_pt)$p.value
reportObject <- compareValues2(reportedValue = "0.002", obtainedValue = p1, valueType = 'p')
p2 <- t.test(df_drop2$AE_pt, df_drop2$E_pt)$p.value
reportObject <- compareValues2(reportedValue = "0.001", obtainedValue = p2, valueType = 'p')
p3 <- t.test(df_drop2$AEA_pt, df_drop2$E_pt)$p.value
reportObject <- compareValues2(reportedValue = "0.683", obtainedValue = p3, valueType = 'p')
```

All values match. Let's try and reproduce these outcomes:

> A one-way ANOVA revealed a significant effect of conditions (F(2, 36) = 20.62, p < 0.001) on the standardized difference scores (where the difference scores for each participant in the E condition was subtracted from his or her difference score in the EA, AE, and AEA conditions).

```{r}
diffs <- df_drop2 %>% mutate(EA_diff = EA_pt - E_pt, AE_diff = AE_pt - E_pt, AEA_diff = AEA_pt - E_pt) # calculate difference scores

# tidy dataframe
df_diffs <- diffs %>% gather(condition, diffScore, EA_diff:AEA_diff, factor_key=TRUE) %>% select(Sbj, condition, diffScore) %>% mutate(Sbj = factor(Sbj))

# calculate repeated measures anova
aov1 <- aov(diffScore ~ condition + Error(Sbj/condition), data=df_diffs)
summary(aov1)
aov1 <- tidy(aov1$`Sbj:condition`)
aovF <- aov1 %>% filter(term == "condition") %>% pull(statistic)
aovDF1 <- aov1 %>% filter(term == "condition") %>% pull(df)
aovDF2 <- aov1 %>% filter(term == "Residuals") %>% pull(df)
aovP <- aov1 %>% filter(term == "condition") %>% pull(p.value)

reportObject <- compareValues2(reportedValue = "2", obtainedValue = aovDF1, valueType = 'df')
reportObject <- compareValues2(reportedValue = "36", obtainedValue = aovDF2, valueType = 'df')
reportObject <- compareValues2(reportedValue = "20.62", obtainedValue = aovF, valueType = 'F')
reportObject <- compareValues2(reportedValue = "eyeballMATCH", obtainedValue = aovP, valueType = 'p')
```
Values appear to match.

> The post hoc tests revealed that the standardized difference scores were larger (more positive) in the EA condition than in the AE and AEA conditions (p = 0.000 and p = 0.012 respectively). The standardized difference score was smaller (less positive) in the AE condition than in the AEA condition (p = 0.003). In summary, temporal binding occurred both when an action triggered an event and when an event triggered an action. However, the binding (as indicated by a smaller perceived delay) was decreased when an action followed an action – event sequence.

```{r}
EA_diffs <- df_diffs %>% filter(condition == "EA_diff") %>% pull(diffScore)
AE_diffs <- df_diffs %>% filter(condition == "AE_diff") %>% pull(diffScore)
AEA_diffs <- df_diffs %>% filter(condition == "AEA_diff") %>% pull(diffScore)

p5 <- t.test(EA_diffs,AE_diffs, paired = T)$p.value

reportObject <- compareValues2(reportedValue = "eyeballMATCH", obtainedValue = p5, valueType = 'p')

p6 <- t.test(EA_diffs,AEA_diffs, paired = T)$p.value
reportObject <- compareValues2(reportedValue = "0.012", obtainedValue = p6, valueType = 'p')

p7 <- t.test(AE_diffs,AEA_diffs, paired = T)$p.value
reportObject <- compareValues2(reportedValue = "0.003", obtainedValue = p7, valueType = 'p')
```

p value for EA vs AEA and AE vs AEA are reroduced. Reported p-value of 0.000 for EA vs AE must be incorrect but seems reasonable to assume authors mean p < .001 so we will code this as a match.

## Step 5: Conclusion

At first there was insufficient information to continue with the analysis: we did not have sufficient information to identify two excluded participants and then two inferential tests were not explicitly identified. This information was shared with us by the original authors, and subsequently we were able to successfully reproduce all target outcomes.

```{r}
reportObject$Article_ID <- "Tbkij"
reportObject$affectsConclusion <- NA
reportObject$error_typo <- 0
reportObject$error_specification <- 0
reportObject$error_analysis <- 0
reportObject$error_data <- 0
reportObject$error_unidentified <- 0
reportObject$Author_Assistance <- T
reportObject$resolved_typo <- 0
reportObject$resolved_specification <- 4
reportObject$resolved_analysis <- 0
reportObject$resolved_data <- 0
reportObject$correctionSuggested <- "no"
reportObject$correctionPublished <- F

# decide on final outcome
if(reportObject$Decision_Errors > 0 | reportObject$Major_Numerical_Errors > 0 | reportObject$Insufficient_Information_Errors > 0){
  reportObject$finalOutcome <- "Failure"
  if(reportObject$Author_Assistance == T){
    reportObject$finalOutcome <- "Failure despite author assistance"
  }
}else{
  reportObject$finalOutcome <- "Success"
  if(reportObject$Author_Assistance == T){
    reportObject$finalOutcome <- "Success with author assistance"
  }
}

# save the report object
filename <- paste0("reportObject_", reportObject$Article_ID,".csv")
write_csv(reportObject, filename)
```

## Report Object

```{r, echo = FALSE}
# display report object in chunks
kable(reportObject[2:10], align = 'l')
kable(reportObject[11:20], align = 'l')
kable(reportObject[21:25], align = 'l')
kable(reportObject[26:30], align = 'l')
kable(reportObject[31:35], align = 'l')
kable(reportObject[36:40], align = 'l')
kable(reportObject[41:45], align = 'l')
kable(reportObject[46:51], align = 'l')
kable(reportObject[52:57], align = 'l')
```

## Session information

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
